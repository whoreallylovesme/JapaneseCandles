{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPk6qmwaql1j3wozo7lDOPP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "id": "Njzi2LGV6tzP"
      },
      "outputs": [],
      "source": [
        "# importing some PySpark libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "# importing some python3 libraries\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# без этой строчки про парсер ничего работать не будет\n",
        "# (как я понял это проблемы современного спарка)\n",
        "spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .appName(\"SparkTask\") \\\n",
        "        .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "input_csv = \"fin_sample.csv\"\n",
        "path = input(\"Enter PATH to CSV file or just press ENTER for std df: \")\n",
        "if (path):\n",
        "    input_csv = path"
      ],
      "metadata": {
        "id": "vhfp8j-bCZRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4572055-3a34-48ef-d56a-fb530abf50ad"
      },
      "execution_count": 236,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter PATH to CSV file or just press ENTER for std df: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading df\n",
        "schema = StructType([\n",
        "    StructField(\"#SYMBOL\", StringType(), True),\n",
        "    StructField(\"SYSTEM\", StringType(), True),\n",
        "    StructField(\"MOMENT\", StringType(), True),\n",
        "    StructField(\"ID_DEAL\", LongType(), True),\n",
        "    StructField(\"PRICE_DEAL\", DoubleType(), True),\n",
        "    StructField(\"VOLUME\", LongType(), True),\n",
        "    StructField(\"OPEN_POS\", LongType(), True),\n",
        "    StructField(\"DIRECTION\", StringType(), True),\n",
        "])\n",
        "df = spark.read.csv(input_csv, header=True, schema=schema)\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpLn1JogDFAZ",
        "outputId": "ae98f969-8f65-4e51-cb4b-e21e4e875a11"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-----------------+---------+----------+------+--------+---------+\n",
            "|#SYMBOL|SYSTEM|           MOMENT|  ID_DEAL|PRICE_DEAL|VOLUME|OPEN_POS|DIRECTION|\n",
            "+-------+------+-----------------+---------+----------+------+--------+---------+\n",
            "|   RIZ1|     F|20111130190000307|463365797|  154680.0|     1|  949182|        B|\n",
            "|   RIZ1|     F|20111130190000547|463365798|  155000.0|     1|  949186|        B|\n",
            "|   RIZ1|     F|20111130190000547|463365799|  155000.0|     1|  949186|        B|\n",
            "|   RIZ1|     F|20111130190000547|463365800|  155200.0|     1|  949186|        B|\n",
            "|   RIZ1|     F|20111130190001200|463365801|  155555.0|     1|  949190|        B|\n",
            "+-------+------+-----------------+---------+----------+------+--------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# just setting std options\n",
        "options = {}\n",
        "options[\"candle.width\"] = 300000\n",
        "options[\"candle.date.from\"] = 19000101\n",
        "options[\"candle.date.to\"] = 20200101\n",
        "options[\"candle.time.from\"] = 1000\n",
        "options[\"candle.time.to\"] = 2000\n",
        "\n",
        "# parsing xml config file from command line argument\n",
        "xml_file_path = input(\n",
        "    \"Enter PATH to XML config file or just press ENTER for std options: \"\n",
        ")\n",
        "if (xml_file_path):\n",
        "    tree = xml.etree.ElementTree.parse(xml_file_path)\n",
        "    root = tree.getroot()\n",
        "    for prop in root.findall('property'):\n",
        "        name = prop.find('name').text\n",
        "        value = prop.find('value').text\n",
        "        options[name] = value"
      ],
      "metadata": {
        "id": "RbT4mMa7DS_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b66282a-805a-411e-db6b-10e84cf05b70"
      },
      "execution_count": 238,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter PATH to XML config file or just press ENTER for std options: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to TIMESTAMP format\n",
        "df = df.withColumn(\"MOMENT\", F.to_timestamp(\"MOMENT\", \"yyyyMMddHHmmssSSS\"))\n",
        "\n",
        "# filtering according options\n",
        "df = df.filter(\n",
        "    (F.hour(\"MOMENT\") * 100 + F.minute(\"MOMENT\") >= options[\"candle.time.from\"]) &\n",
        "    (F.hour(\"MOMENT\") * 100 + F.minute(\"MOMENT\") <= options[\"candle.time.to\"])\n",
        ")\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-rmIA_vNEZu",
        "outputId": "e2e26e7a-8ffd-43e9-e026-5a01108850a9"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+--------------------+---------+----------+------+--------+---------+\n",
            "|#SYMBOL|SYSTEM|              MOMENT|  ID_DEAL|PRICE_DEAL|VOLUME|OPEN_POS|DIRECTION|\n",
            "+-------+------+--------------------+---------+----------+------+--------+---------+\n",
            "|   RIZ1|     F|2011-11-30 19:00:...|463365797|  154680.0|     1|  949182|        B|\n",
            "|   RIZ1|     F|2011-11-30 19:00:...|463365798|  155000.0|     1|  949186|        B|\n",
            "|   RIZ1|     F|2011-11-30 19:00:...|463365799|  155000.0|     1|  949186|        B|\n",
            "|   RIZ1|     F|2011-11-30 19:00:...|463365800|  155200.0|     1|  949186|        B|\n",
            "|   RIZ1|     F|2011-11-30 19:00:...|463365801|  155555.0|     1|  949190|        B|\n",
            "+-------+------+--------------------+---------+----------+------+--------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making candlesticks\n",
        "\n",
        "# splitting by time windows\n",
        "window_spec = F.window(\"MOMENT\", f\"{options['candle.width']} milliseconds\")\n",
        "\n",
        "# group by #SYMBOL and time windows\n",
        "# then aggregate it for answer according aliases\n",
        "candlestick_df = df.groupBy(\"#SYMBOL\", window_spec).agg(\n",
        "    F.first(\"PRICE_DEAL\").alias(\"OPEN\"),\n",
        "    F.max(\"PRICE_DEAL\").alias(\"HIGH\"),\n",
        "    F.min(\"PRICE_DEAL\").alias(\"LOW\"),\n",
        "    F.last(\"PRICE_DEAL\").alias(\"CLOSE\"),\n",
        "    F.sum(\"VOLUME\").alias(\"Volume\")\n",
        ")\n",
        "\n",
        "# select required columns for answer\n",
        "candlestick_df = candlestick_df.select(\n",
        "    F.col(\"#SYMBOL\"),\n",
        "    F.col(\"window.start\").alias(\"MOMENT\"),\n",
        "    \"OPEN\",\n",
        "    \"HIGH\",\n",
        "    \"LOW\",\n",
        "    \"CLOSE\"\n",
        ")\n",
        "\n",
        "# order by time (ascending)\n",
        "candlestick_df = candlestick_df.orderBy(\"#SYMBOL\", \"MOMENT\")\n",
        "\n",
        "# converting back to yyyyMMddHHmmssSSS from TIMESTAMP\n",
        "candlestick_df = candlestick_df.withColumn(\n",
        "    \"MOMENT\",\n",
        "    F.date_format(\"MOMENT\", \"yyyyMMddHHmmssSSS\")\n",
        ")\n",
        "\n",
        "candlestick_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l16QydmtTELN",
        "outputId": "87cf6b8d-e53c-4e81-e5c5-243ad209be3c"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+------+------+------+------+\n",
            "|#SYMBOL|           MOMENT|  OPEN|  HIGH|   LOW| CLOSE|\n",
            "+-------+-----------------+------+------+------+------+\n",
            "|   AUZ1|20111130190000000|1.0265|1.0265|1.0265|1.0265|\n",
            "|   AUZ1|20111130192000000| 1.026| 1.026| 1.026| 1.026|\n",
            "|   AUZ1|20111130192500000|1.0265|1.0265|1.0265|1.0265|\n",
            "|   AUZ1|20111130195000000|1.0262|1.0262|1.0262|1.0262|\n",
            "|   BRZ1|20111130190000000|111.86|111.98|111.67|111.68|\n",
            "+-------+-----------------+------+------+------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# writing answer\n",
        "\n",
        "# selecting unique #SYMBOL\n",
        "unique_symbols = candlestick_df \\\n",
        "                 .select(\"#SYMBOL\") \\\n",
        "                 .distinct() \\\n",
        "                 .rdd \\\n",
        "                 .flatMap(lambda x: x) \\\n",
        "                 .collect()\n",
        "\n",
        "output_dir = \"AnswerSparkTask\"\n",
        "\n",
        "# rm -r output_dir\n",
        "if os.path.exists(output_dir):\n",
        "    shutil.rmtree(output_dir)\n",
        "os.makedirs(output_dir)\n",
        "\n",
        "# writing answer to files\n",
        "for symbol in unique_symbols:\n",
        "    symbol_df = candlestick_df.filter(F.col(\"#SYMBOL\") == symbol)\n",
        "    output_path = os.path.join(output_dir, f\"{symbol}.csv\")\n",
        "    symbol_df.write.csv(output_path, header=True, mode=\"overwrite\")\n",
        "\n",
        "    # print some logs\n",
        "    print(f\"Saved candlestick data for {symbol} to {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgxIrRC8lIYA",
        "outputId": "3a1e3124-ef3c-4e20-b2dc-703bfd8e696a"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved candlestick data for TTZ1 to AnswerSparkTask/TTZ1.csv\n",
            "Saved candlestick data for SPZ1 to AnswerSparkTask/SPZ1.csv\n",
            "Saved candlestick data for CUZ1 to AnswerSparkTask/CUZ1.csv\n",
            "Saved candlestick data for O4H2 to AnswerSparkTask/O4H2.csv\n",
            "Saved candlestick data for LKM2 to AnswerSparkTask/LKM2.csv\n",
            "Saved candlestick data for PTZ1 to AnswerSparkTask/PTZ1.csv\n",
            "Saved candlestick data for RNZ1 to AnswerSparkTask/RNZ1.csv\n",
            "Saved candlestick data for FSZ1 to AnswerSparkTask/FSZ1.csv\n",
            "Saved candlestick data for GZZ1 to AnswerSparkTask/GZZ1.csv\n",
            "Saved candlestick data for SiM2 to AnswerSparkTask/SiM2.csv\n",
            "Saved candlestick data for VBH2 to AnswerSparkTask/VBH2.csv\n",
            "Saved candlestick data for SGZ1 to AnswerSparkTask/SGZ1.csv\n",
            "Saved candlestick data for LKZ1 to AnswerSparkTask/LKZ1.csv\n",
            "Saved candlestick data for VXZ1 to AnswerSparkTask/VXZ1.csv\n",
            "Saved candlestick data for SRZ1 to AnswerSparkTask/SRZ1.csv\n",
            "Saved candlestick data for GDZ1 to AnswerSparkTask/GDZ1.csv\n",
            "Saved candlestick data for LKH2 to AnswerSparkTask/LKH2.csv\n",
            "Saved candlestick data for RIZ1 to AnswerSparkTask/RIZ1.csv\n",
            "Saved candlestick data for SRM2 to AnswerSparkTask/SRM2.csv\n",
            "Saved candlestick data for GZH2 to AnswerSparkTask/GZH2.csv\n",
            "Saved candlestick data for RIM5 to AnswerSparkTask/RIM5.csv\n",
            "Saved candlestick data for RSH2 to AnswerSparkTask/RSH2.csv\n",
            "Saved candlestick data for SiZ1 to AnswerSparkTask/SiZ1.csv\n",
            "Saved candlestick data for SVZ1 to AnswerSparkTask/SVZ1.csv\n",
            "Saved candlestick data for NKH2 to AnswerSparkTask/NKH2.csv\n",
            "Saved candlestick data for SRH2 to AnswerSparkTask/SRH2.csv\n",
            "Saved candlestick data for SVH2 to AnswerSparkTask/SVH2.csv\n",
            "Saved candlestick data for RSZ1 to AnswerSparkTask/RSZ1.csv\n",
            "Saved candlestick data for MXZ1 to AnswerSparkTask/MXZ1.csv\n",
            "Saved candlestick data for SNH2 to AnswerSparkTask/SNH2.csv\n",
            "Saved candlestick data for EDZ1 to AnswerSparkTask/EDZ1.csv\n",
            "Saved candlestick data for SAH2 to AnswerSparkTask/SAH2.csv\n",
            "Saved candlestick data for GDH2 to AnswerSparkTask/GDH2.csv\n",
            "Saved candlestick data for BRZ1 to AnswerSparkTask/BRZ1.csv\n",
            "Saved candlestick data for NKZ1 to AnswerSparkTask/NKZ1.csv\n",
            "Saved candlestick data for GMZ1 to AnswerSparkTask/GMZ1.csv\n",
            "Saved candlestick data for HYZ1 to AnswerSparkTask/HYZ1.csv\n",
            "Saved candlestick data for PDZ1 to AnswerSparkTask/PDZ1.csv\n",
            "Saved candlestick data for VBZ1 to AnswerSparkTask/VBZ1.csv\n",
            "Saved candlestick data for RIH2 to AnswerSparkTask/RIH2.csv\n",
            "Saved candlestick data for SNZ1 to AnswerSparkTask/SNZ1.csv\n",
            "Saved candlestick data for SPH2 to AnswerSparkTask/SPH2.csv\n",
            "Saved candlestick data for CHZ1 to AnswerSparkTask/CHZ1.csv\n",
            "Saved candlestick data for AUZ1 to AnswerSparkTask/AUZ1.csv\n",
            "Saved candlestick data for SiH2 to AnswerSparkTask/SiH2.csv\n",
            "Saved candlestick data for TNH2 to AnswerSparkTask/TNH2.csv\n",
            "Saved candlestick data for EuZ1 to AnswerSparkTask/EuZ1.csv\n",
            "Saved candlestick data for GUZ1 to AnswerSparkTask/GUZ1.csv\n"
          ]
        }
      ]
    }
  ]
}